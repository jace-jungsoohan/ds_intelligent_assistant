
from typing import Any, Dict
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough
from langchain_google_vertexai import ChatVertexAI
from app.core.config import settings
from packages.bq_wrapper.schema import get_table_info
from packages.bq_wrapper.client import BigQueryWrapper




# Initialize Vertex AI Chat Model
# Ensure your environment has Google Cloud credentials set up

try:



    llm = ChatVertexAI(
        model_name="gemini-2.5-flash",
        project=settings.PROJECT_ID,
        location=settings.LOCATION,
        temperature=0,
        max_output_tokens=2048
    )
except Exception as e:
    print(f"Warning: Could not initialize Vertex AI: {e}")
    llm = None

bq_client = BigQueryWrapper()

# 1. SQL Generation Step
template_sql_gen = """
You are a BigQuery expert for a logistics company named Willog.
Your goal is to answer user questions by generating a valid Standard SQL query.

Dataset: `willog-prod-data-gold.rag`

Available tables (always use fully qualified names with backticks):

1. `willog-prod-data-gold.rag.mart_logistics_master` (Fact Table)
   - Purpose: Master transport stats, volume, damage rates, RISK LEVELS, FATIGUE.
   - Columns: 
     - code (STRING): Shipment ID
     - departure_date (DATE): Partition Key - use for time filtering (e.g., "ì´ë²ˆ ë‹¬", "ìµœê·¼ 1ì£¼ì¼")
     - destination (STRING): Port code (e.g., 'CNSHG')
     - product (STRING)
     - transport_mode (STRING): 'air', 'truck', 'ocean+ferry', 'ocean+rail' (Note: Raw data is lowercase. 'ocean' often appears in composites.)
     - package_type (STRING): Packaging type
     - cumulative_shock_index (FLOAT): "Fatigue" or "Cumulative Stress" score
     - risk_level (STRING): 'Low', 'Medium', 'High', 'Critical'
     - temp_excursion_duration_min (INT64): Minutes outside valid temp range
     - is_damaged (BOOL): Damage flag

2. `willog-prod-data-gold.rag.mart_sensor_detail` (Big Data / Granular)
   - Purpose: Dynamic Threshold Queries (e.g. "Shock > 7G"), Multi-variable Correlation, Directional Analysis.
   - Columns: 
     - event_date (DATE): Partition Key - use for time filtering
     - code (STRING): Shipment ID (Join Key)
     - destination (STRING): Port code
     - destination_country (STRING): 'China', 'Japan', 'Vietnam', 'Korea', 'USA', 'Other'
     - transport_mode (STRING): 'air', 'truck', 'ocean+ferry', 'ocean+rail' - DIRECTLY AVAILABLE. Use lowercase or LIKE '%ocean%'.
     - shock_g (FLOAT), temperature (FLOAT), humidity (FLOAT)
     - acc_x, acc_y, acc_z (FLOAT): Directional acceleration
     - tilt_x, tilt_y (FLOAT): Tilt angles
     - lat, lon (FLOAT): Geolocation

3. `willog-prod-data-gold.rag.mart_risk_heatmap` (Geospatial)
   - Purpose: "Heatmap", "Risk Map", "Where do shocks occur?".
   - Columns: lat_center, lon_center, location_label, risk_score, high_impact_events

4. `willog-prod-data-gold.rag.mart_quality_matrix` (Benchmarking)
   - Purpose: Compare Performance (A vs B), Benchmarking Packaging/Routes.
   - Columns: transport_mode, package_type, route, damage_rate, avg_fatigue_score, safety_score

Scenario Guidelines (Whitepaper Analytics):
- **Fatigue/Stress**: Query `cumulative_shock_index` from `mart_logistics_master`.
- **Benchmarking/Comparison**: Query `mart_quality_matrix`.
- **Composite Conditions (e.g. Temp < 0 & Shock > 5)**: Query `mart_sensor_detail`.
- **Country filtering**: Use `destination_country` in `mart_sensor_detail` (e.g., WHERE destination_country = 'China').
- **Transport Mode**: Use LOWERCASE values ('ocean', 'air', 'truck') or `LIKE` for safety (e.g. `WHERE transport_mode LIKE 'ocean%'`).
- **Time filtering**: Use `departure_date` or `event_date` with DATE functions:
  - "ì´ë²ˆ ë‹¬": `WHERE event_date >= DATE_TRUNC(CURRENT_DATE(), MONTH)`
  - "ìµœê·¼ 1ì£¼ì¼": `WHERE event_date >= DATE_SUB(CURRENT_DATE(), INTERVAL 7 DAY)`
  - "ì§€ë‚œë‹¬": `WHERE event_date BETWEEN DATE_TRUNC(DATE_SUB(CURRENT_DATE(), INTERVAL 1 MONTH), MONTH) AND LAST_DAY(DATE_SUB(CURRENT_DATE(), INTERVAL 1 MONTH))`
- **Ambiguity Prevention**: ALWAYS use table aliases (e.g. `t1.code`, `t2.destination`) when joining tables. Columns `code` and `destination` exist in multiple tables execution will fail if not qualified.

Code Mapping Guide (Interpret location names as follows):
- Shanghai, Sanghai, ìƒí•´, ìƒí•˜ì´, SH -> 'CNSHG'
- Osaka, Osaca, ì˜¤ì‚¬ì¹´, ì˜¤ì‚¬ì¹´í•­ -> 'JPOSA'
- Rizhao, Rizo, ì¼ì¡°, ë¦¬ìì˜¤ -> 'CNRZH'
- Lianyungang, Lianyun, ì—°ìš´í•­ -> 'CNLYG'
- Ningbo, Ningpo, ë‹ë³´ -> 'CNNBG'
- Hochiminh, HCMC, í˜¸ì¹˜ë¯¼ -> 'VNSGN' (or like '%VN%')
- Haiphong, í•˜ì´í -> 'VNHPH'
- Incheon, ICN, ì¸ì²œ -> 'KRICN'
- Busan, Pusan, ë¶€ì‚° -> 'KRPUS'
- China, ì¤‘êµ­ -> destination_country = 'China' OR destination LIKE 'CN%'
- Vietnam, ë² íŠ¸ë‚¨ -> destination_country = 'Vietnam' OR destination LIKE 'VN%'
- Japan, ì¼ë³¸ -> destination_country = 'Japan' OR destination LIKE 'JP%'

Example SQLs (Few-shot Learning):
1. "ğŸ›³ï¸ í•´ìƒ ìš´ì†¡ ì¤‘ 5G ì´ìƒ ì¶©ê²© ë°œìƒ ë¹„ìœ¨" (Ratio Calculation)
SELECT
    t2.transport_mode,
    COUNTIF(t1.shock_g >= 5) as high_shock_count,
    COUNT(*) as total_sensor_readings,
    SAFE_DIVIDE(COUNTIF(t1.shock_g >= 5), COUNT(*)) as high_shock_ratio
FROM `willog-prod-data-gold.rag.mart_sensor_detail` t1
JOIN `willog-prod-data-gold.rag.mart_logistics_master` t2 ON t1.code = t2.code
WHERE t2.transport_mode LIKE 'ocean%' -- Use LIKE for safety or 'ocean'
GROUP BY 1

2. "ë² íŠ¸ë‚¨í–‰ í™”ë¬¼ ì¤‘ ìŠµë„ ì´íƒˆ êµ¬ê°„" (Route/Location Analysis)
SELECT lat, lon, COUNT(*) as excursion_count
FROM `willog-prod-data-gold.rag.mart_sensor_detail`
WHERE destination LIKE '%VN%' OR destination = 'VNSGN' -- ERROR: Destination not in sensor_detail
-- CORRECT APPROACH:
-- SELECT t1.lat, t1.lon, COUNT(*) 
-- FROM `willog-prod-data-gold.rag.mart_sensor_detail` t1
-- JOIN `willog-prod-data-gold.rag.mart_logistics_master` t2 ON t1.code = t2.code
-- WHERE t2.destination LIKE '%VN%' ...

3. "ì´ë²ˆ ë‹¬ ì¤‘êµ­ì—ì„œ ì˜í•˜ ì˜¨ë„ ì¶©ê²© ê±´ìˆ˜" (Location + Sensor Condition)
SELECT
    COUNT(*) as shock_count_below_zero
FROM `willog-prod-data-gold.rag.mart_sensor_detail` t1
JOIN `willog-prod-data-gold.rag.mart_logistics_master` t2 ON t1.code = t2.code
WHERE
    t2.destination LIKE '%China%' OR t2.destination IN ('CNSHG', 'CNNBG', 'CNRZH', 'CNLYG')
    AND t1.temperature < 0
    AND t1.shock_g > 0 
    AND t1.event_date BETWEEN DATE_TRUNC(CURRENT_DATE(), MONTH) AND CURRENT_DATE()

4. "â„ï¸ 60ë¶„ì´ìƒ ì§€ì†ëœ ì˜í•˜ ì˜¨ë„ì—ì„œ ë°œìƒí•œ ì¶©ê²© ê±´ìˆ˜" (Duration + Complex Condition)
-- 'Duration' queries usually refer to 'temp_excursion_duration_min' in master table.
SELECT
    COUNT(*) as shock_count
FROM `willog-prod-data-gold.rag.mart_sensor_detail` t1
JOIN `willog-prod-data-gold.rag.mart_logistics_master` t2 ON t1.code = t2.code
WHERE
    t1.temperature < 0
    AND t2.temp_excursion_duration_min >= 60 -- Use pre-calculated duration from master
    AND t1.shock_g > 0



Previous Conversation Context:
{chat_history}

Question: {question}
SQL Query:
"""

prompt_sql_gen = ChatPromptTemplate.from_template(template_sql_gen)

def get_schema(_):
    return get_table_info()



if llm:
    sql_generator_chain = (
        prompt_sql_gen
        | llm
        | StrOutputParser()
    )
else:
    # Mock chain if LLM is not available
    class MockSQLChain:
        def invoke(self, input_dict):
            return "```sql\n-- Mock SQL (LLM unavailable)\nSELECT * FROM view_transport_stats LIMIT 10\n```"
    sql_generator_chain = MockSQLChain()

# 2. Response Synthesis Prompt
template_synthesis = """
You are a helpful assistant for Willog logistics.
Based on the SQL query result, provide a natural language answer to the user's question.
Answer in Korean (í•œêµ­ì–´).

User Question: {question}
SQL Query: {sql}
Query Result: {result}

If the result is empty or says "(empty)", say "í•´ë‹¹ ì¡°ê±´ì— ë§ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
Otherwise, summarize the key findings from the result.
Do NOT say there is no data if values are present.

Answer:
"""

prompt_synthesis = ChatPromptTemplate.from_template(template_synthesis)

if llm:
    synthesis_chain = prompt_synthesis | llm | StrOutputParser()
else:
    synthesis_chain = None

class SQLAgent:
    def __init__(self):
        self.chain = sql_generator_chain
        self.synthesis_chain = synthesis_chain
    
    def process_query(self, question: str, chat_history: list = None) -> Dict[str, Any]:
        from datetime import date
        current_date = date.today().isoformat()
        
        # Format history logic
        history_str = ""
        if chat_history:
            recent_history = chat_history[-6:] # Context window 6
            for msg in recent_history:
                role = "User" if msg.get("role") == "user" else "Assistant"
                content = msg.get("content", "")
                history_str += f"{role}: {content}\n"

        # 1. Generate SQL
        generated_sql = self.chain.invoke({
            "question": question, 
            "current_date": current_date,
            "chat_history": history_str
        })
        
        print(f"DEBUG: Generated SQL for '{question}': [{generated_sql}]") # Debug log
        
        clean_sql = generated_sql.replace("```sql", "").replace("```", "").strip()
        
        if not clean_sql:
            return {
                "question": question,
                "generated_sql": "",
                "result": None,
                "natural_response": "SQL ìƒì„± ì‹¤íŒ¨: ì§ˆë¬¸ì„ ì´í•´í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.",
                "error": "Empty SQL generated"
            }
        
        # 2. Execute SQL against BigQuery
        result_df = None
        error = None
        try:
            if bq_client.client:
                print(f"DEBUG: Executing query on BigQuery...")
                result_df = bq_client.run_query(clean_sql)
                print(f"DEBUG: Query executed. Result shape: {result_df.shape if result_df is not None else 'None'}")
            else:
                error = "BigQuery Client is not initialized (client object is None)."
                print(f"DEBUG: {error}")
        except Exception as e:
            error = str(e)
            print(f"DEBUG: Query execution failed: {error}")

        # 3. Synthesize natural language response
        natural_response = None
        if result_df is not None and self.synthesis_chain:
            try:
                # Convert DataFrame to string for LLM
                result_str = result_df.to_string() if not result_df.empty else "(empty)"
                print(f"DEBUG: Synthesis Input Result:\n{result_str}")
                natural_response = self.synthesis_chain.invoke({
                    "question": question,
                    "sql": clean_sql,
                    "result": result_str
                })
            except Exception as e:
                natural_response = f"ê²°ê³¼ í•´ì„ ì¤‘ ì˜¤ë¥˜: {e}"
        elif error:
            natural_response = f"ì¿¼ë¦¬ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {error}"
        elif result_df is None:
            # Fallback for unexpected None result without explicit error
            natural_response = (
                f"âš ï¸ ë°ì´í„° ì¡°íšŒì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.\n"
                f"SQLì€ ìƒì„±ë˜ì—ˆìœ¼ë‚˜ BigQuery ì‹¤í–‰ ê²°ê³¼ë¥¼ ë°›ì•„ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.\n"
                f"ë””ë²„ê·¸ ì •ë³´:\n"
                f"- SQL: `{clean_sql}`\n"
                f"- BQ Client Status: {'Active' if bq_client.client else 'Inactive'}"
            )

        return {
            "question": question,
            "generated_sql": clean_sql,
            "result": result_df,
            "natural_response": natural_response,
            "error": error
        }

agent = SQLAgent()
